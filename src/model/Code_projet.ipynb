{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # pour la manipulation de dataframes\n",
    "import seaborn as sns # pour la visualisation\n",
    "import matplotlib.pyplot as plt # pour la visualisation\n",
    "import numpy as np # manipulation de tableaux\n",
    "from sklearn.model_selection import train_test_split    # pour diviser les données en train et test sets\n",
    "np.random.seed(42) # pour la reproductbilité des opérations aléatoires\n",
    "from mord import LogisticAT\n",
    "from typing import List\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from mord import LogisticAT, OrdinalRidge\n",
    "import pickle\n",
    "from sklearn.linear_model import LassoLarsIC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture de la base et traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52257 entries, 0 to 52256\n",
      "Data columns (total 33 columns):\n",
      " #   Column                                   Non-Null Count  Dtype  \n",
      "---  ------                                   --------------  -----  \n",
      " 0   energy_100g                              52257 non-null  float64\n",
      " 1   fat_100g                                 52257 non-null  float64\n",
      " 2   saturated-fat_100g                       52257 non-null  float64\n",
      " 3   trans-fat_100g                           52084 non-null  float64\n",
      " 4   cholesterol_100g                         52164 non-null  float64\n",
      " 5   carbohydrates_100g                       52257 non-null  float64\n",
      " 6   sugars_100g                              52257 non-null  float64\n",
      " 7   fiber_100g                               52257 non-null  float64\n",
      " 8   proteins_100g                            52257 non-null  float64\n",
      " 9   salt_100g                                52257 non-null  float64\n",
      " 10  sodium_100g                              52257 non-null  float64\n",
      " 11  vitamin-a_100g                           52164 non-null  float64\n",
      " 12  vitamin-c_100g                           52240 non-null  float64\n",
      " 13  calcium_100g                             52164 non-null  float64\n",
      " 14  iron_100g                                52184 non-null  float64\n",
      " 15  nutrition-score-fr_100g                  52257 non-null  float64\n",
      " 16  code                                     52257 non-null  int64  \n",
      " 17  creator                                  52257 non-null  object \n",
      " 18  created_t                                52257 non-null  object \n",
      " 19  last_modified_t                          52257 non-null  object \n",
      " 20  product_name                             51983 non-null  object \n",
      " 21  brands                                   51997 non-null  object \n",
      " 22  countries                                52257 non-null  object \n",
      " 23  countries_fr                             52257 non-null  object \n",
      " 24  ingredients_text                         34466 non-null  object \n",
      " 25  serving_size                             20457 non-null  object \n",
      " 26  additives_n                              34466 non-null  float64\n",
      " 27  additives                                34458 non-null  object \n",
      " 28  additives_tags                           21802 non-null  object \n",
      " 29  additives_fr                             21802 non-null  object \n",
      " 30  ingredients_from_palm_oil_n              34466 non-null  float64\n",
      " 31  ingredients_that_may_be_from_palm_oil_n  34466 non-null  float64\n",
      " 32  nutrition_grade_fr                       52257 non-null  object \n",
      "dtypes: float64(19), int64(1), object(13)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_aliments = pd.read_csv(\"C://Cours M2 S1//Conférences, SAS, VBA, Gestion de projet//Gestion de projet digital//data_clean_principal.csv\")\n",
    "df_aliments.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va retirer les colonnes avec trop de données manquantes pour éviter une trop grande perte de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppresion des colonnes qui ne nous intéresse pas\n",
    "df_aliments.drop(df_aliments.columns[15:32], axis=1, inplace=True)\n",
    "# suppression des na restants\n",
    "df_aliments.dropna(inplace=True)\n",
    "# suppression des doublons\n",
    "df_aliments.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 52082 entries, 173 to 52256\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   energy_100g         52082 non-null  float64\n",
      " 1   fat_100g            52082 non-null  float64\n",
      " 2   saturated-fat_100g  52082 non-null  float64\n",
      " 3   trans-fat_100g      52082 non-null  float64\n",
      " 4   cholesterol_100g    52082 non-null  float64\n",
      " 5   carbohydrates_100g  52082 non-null  float64\n",
      " 6   sugars_100g         52082 non-null  float64\n",
      " 7   fiber_100g          52082 non-null  float64\n",
      " 8   proteins_100g       52082 non-null  float64\n",
      " 9   salt_100g           52082 non-null  float64\n",
      " 10  sodium_100g         52082 non-null  float64\n",
      " 11  vitamin-a_100g      52082 non-null  float64\n",
      " 12  vitamin-c_100g      52082 non-null  float64\n",
      " 13  calcium_100g        52082 non-null  float64\n",
      " 14  iron_100g           52082 non-null  float64\n",
      " 15  nutrition_grade_fr  52082 non-null  object \n",
      "dtypes: float64(15), object(1)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_aliments.info() # informations globales sur le dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des données de type numérique + variable d'intérêt (nutriscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On code chaque nutriscore en attribuant la plus grande valeur à a (4), puis b (3)...\n",
    "l = list(df_aliments[\"nutrition_grade_fr\"].unique())\n",
    "l.sort(reverse=True)\n",
    "nutri_code = {score.lower() : i for i, score in enumerate(l)}\n",
    "\n",
    "# on enregistre les codes pour réutilisation\n",
    "df_nutri_code = pd.DataFrame(list(nutri_code.items()), columns=['Lettre', 'Valeur'])\n",
    "\n",
    "# passage des lesttres aux codes pour les scores\n",
    "df_aliments[\"nutrition_grade_fr\"] = df_aliments[\"nutrition_grade_fr\"].apply(lambda x: nutri_code[x])\n",
    "df_aliments.rename(columns={\"nutrition_grade_fr\" : \"score\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equilibrage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On compte le nombre d'observation par classe\n",
    "counts = df_aliments['score'].value_counts()\n",
    "# on récupère le min\n",
    "min_samples = counts.min()\n",
    "\n",
    "# on crée un nouveau dataframe pour contenir les données équilibrées\n",
    "df_aliments_eq = pd.DataFrame()\n",
    "# on fait uun rééchantillonage en fixant le nombre d'observations par classe au min calculé précédemment\n",
    "for label in counts.index:\n",
    "    subset = df_aliments[df_aliments['score'] == label].sample(min_samples, random_state=42) # chaque échantillon est tiré aléatoirement et de manière reproductible avec le random seed\n",
    "    df_aliments_eq = pd.concat([df_aliments_eq, subset], axis=0) # on joint les données en lignes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation en données de train et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_aliments_eq, train_size=0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_sets(train_data, test_data):\n",
    "    \"\"\"Fonction qui récupère les dataframes train et test et retourne les vecteurs utiles pour la phase\n",
    "    d'entrainement et test.\n",
    "\n",
    "    Args:\n",
    "        train_data (DataFrame): données d'entrainement pré-traitées\n",
    "        test_data (DataFrame): données de test pré-traitées\n",
    "\n",
    "    Returns:\n",
    "        tuple: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train = train_data.drop(labels=[\"score\"], axis=1).values\n",
    "    y_train = train_data[\"score\"].values\n",
    "\n",
    "    X_test = test_data.drop(labels=[\"score\"], axis=1).values\n",
    "    y_test = test_data[\"score\"].values\n",
    "    \n",
    "    ## On normalise les données\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_sets(train_data=df_train, test_data=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le modèle de régression logistique ordinale initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On regarde les coefficients et l'erreur de classification du modèle global initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On entraîne le modèle initial\n",
    "\n",
    "def model_training(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Fonction pour entrainer le modèle de régression logistique ordinale\n",
    "\n",
    "    Args:\n",
    "        X_train (Array): \n",
    "        X_test (Array): \n",
    "        y_train (Array): \n",
    "        y_test (Array): \n",
    "    \"\"\"\n",
    "\n",
    "    # Maintenant, on utilise les variables sélectionnées pour la régression logistique ordinale avec mord\n",
    "    model_ordinal = LogisticAT(alpha=0)  # On utilise alpha=0 pour ne pas faire de régularisation\n",
    "\n",
    "    # On entraîne le modèle sur les données d'entraînement avec les variables sélectionnées\n",
    "    model_ordinal.fit(X_train, y_train)\n",
    "\n",
    "    # prédictions sur les données de test avec les variables sélectionnées\n",
    "    predictions_ordinal = model_ordinal.predict(X_test)\n",
    "\n",
    "    # Calcul de l'exactitude du modèle de régression logistique ordinale\n",
    "    accuracy_ordinal = accuracy_score(y_test, predictions_ordinal)\n",
    "    \n",
    "    print(\"Coefficients du modèle de régression logistique :\")\n",
    "    print(model_ordinal.coef_)\n",
    "   \n",
    "    print(\"Précision du modèle sur les données de test : {:.2f}%\".format(accuracy_ordinal * 100))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients du modèle de régression logistique :\n",
      "[-8.69434819e-01 -8.68057472e-01 -2.52818495e+00 -6.25123757e-01\n",
      " -1.17822480e+00 -2.90400221e-02 -2.14414845e+00  1.16671310e+00\n",
      "  3.17895485e-01 -1.00605940e+02  9.87390027e+01 -3.81372754e-02\n",
      " -7.46646146e-02 -3.59015259e-01  1.16658539e+00]\n",
      "Précision du modèle sur les données de test : 73.92%\n"
     ]
    }
   ],
   "source": [
    "#On l'applqiue et on montre ses coefficients et son erreur de classification\n",
    "model_training(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression logistique ordinale, pénalisé par la norme L2 (Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On entraîne le modèle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LogisticRegressionCV est utilisé pour effectuer une régression logistique avec une validation croisée pour sélectionner le meilleur paramètre de régularisation (C) parmi une liste de valeurs candidates ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_lasso(train_data, test_data, max_iter = 1000, seuil=0.2):\n",
    "    \"\"\"Fonction pour faire la sélection de variables en se basant sur un modèle Lasso.\n",
    "\n",
    "    Args:\n",
    "        train_data (Dataframe): données préparées pour le train\n",
    "        test_data (DataFrame): données préparées pour le test\n",
    "        max_iter (int, optional): Nombre d'itérations pour obtenir la convergence, par défaut 1000\n",
    "        seuil (float, optional): Valeur seuil en valeur absolur au dessus de laquelle on sélectionn les variables. Par défaut 0.2.\n",
    "\n",
    "    Returns:\n",
    "        tuple: variables_lasso (Liste) noms des variables choisies, X_train_final (Array), X_test_final (Array), y_train(Array), y_test (Array)\n",
    "        vecteurs des variables choisies\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = get_train_test_sets(train_data=train_data, test_data=test_data)\n",
    "    \n",
    "\n",
    "    # modèle de régression logistique avec pénalité L1 (LASSO)\n",
    "    model_lasso = LogisticRegression(penalty='l1', solver='saga', max_iter=max_iter, random_state=None)\n",
    "\n",
    "    # SelectFromModel pour récupérer les paramètres du modèle\n",
    "    sfm = SelectFromModel(estimator=model_lasso)\n",
    "    sfm.fit(X_train, y_train)\n",
    "\n",
    "    # indices des variables sélectionnées\n",
    "    indices_lasso = sfm.get_support(indices=True)\n",
    "    \n",
    "    # noms des variables correspondantes dans les données\n",
    "    variables = [train_data.columns[i] for i in indices_lasso]\n",
    "    \n",
    "    # coefficients des variables sélectionnées\n",
    "    coefficients_lasso = sfm.estimator_.coef_.flatten()\n",
    "\n",
    "    # noms et coefficients des variables\n",
    "    print(\"#########################################################\")\n",
    "    print()\n",
    "    print(\"Coefficients obtenus après Lasso:\")\n",
    "    for variable, coefficient in zip(variables, coefficients_lasso):\n",
    "        print(f\"{variable}: {coefficient}\")\n",
    "\n",
    "    # On pénalise en ne prenant que les coeffs différents au dessus du seuil passé en argument\n",
    "    indices_choisis = [i for i, coef in zip(indices_lasso, coefficients_lasso) if abs(coef) > seuil]\n",
    "\n",
    "    # variables correspondantes aux indices choisies\n",
    "    variables_lasso = [train_data.columns[i] for i in indices_choisis]\n",
    "\n",
    "    print(\"##########################################################\")\n",
    "    print()\n",
    "    print(\"Variables sélectionnées après Lasso\")\n",
    "    print()\n",
    "    for variable in variables_lasso:\n",
    "        print(f\"{variable}\")\n",
    "\n",
    "\n",
    "    # on utilise les indices filtrés pour obtenir les données des variables optimales sélectionnées\n",
    "    X_train_final = X_train[:, indices_choisis]\n",
    "    X_test_final = X_test[:, indices_choisis]\n",
    "    \n",
    "    return variables_lasso, X_train_final, X_test_final, y_train, y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On effectue la régression Lasso optimale en les variables qu'elle a décidé de garder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################################\n",
      "\n",
      "Coefficients obtenus après Lasso:\n",
      "energy_100g: 1.4809457185482384\n",
      "fat_100g: 1.1784745640328433\n",
      "saturated-fat_100g: 5.069634131411031\n",
      "trans-fat_100g: 1.5000700149266886\n",
      "cholesterol_100g: 1.737236853564534\n",
      "carbohydrates_100g: 0.6348773999753657\n",
      "sugars_100g: 2.9465576636099837\n",
      "fiber_100g: -1.9580877559058576\n",
      "proteins_100g: 0.0\n",
      "salt_100g: 1.2797408152624574\n",
      "sodium_100g: 1.2803935971849418\n",
      "vitamin-a_100g: 0.8938012911289186\n",
      "vitamin-c_100g: 0.5016039667485005\n",
      "calcium_100g: 0.0\n",
      "iron_100g: -7.484948492028028\n",
      "##########################################################\n",
      "\n",
      "Variables sélectionnées après Lasso\n",
      "\n",
      "energy_100g\n",
      "fat_100g\n",
      "saturated-fat_100g\n",
      "trans-fat_100g\n",
      "cholesterol_100g\n",
      "carbohydrates_100g\n",
      "sugars_100g\n",
      "fiber_100g\n",
      "salt_100g\n",
      "sodium_100g\n",
      "vitamin-a_100g\n",
      "vitamin-c_100g\n",
      "iron_100g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_, X_train_lasso, X_test_lasso, y_train, y_test = selection_lasso(train_data=df_train, test_data=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On l'entraîne pour nous donné son erreur de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(X_train, X_test, y_train, y_test, selection_method = 'lasso'):\n",
    "    \"\"\"Fonction pour entrainer le modèle de régression logistique ordinale\n",
    "\n",
    "    Args:\n",
    "        X_train (Array): \n",
    "        X_test (Array): \n",
    "        y_train (Array): \n",
    "        y_test (Array): \n",
    "    \"\"\"\n",
    "\n",
    "    # Maintenant, on utilise les variables sélectionnées pour la régression logistique ordinale avec mord\n",
    "    model_ordinal = LogisticAT(alpha=0)  # On utilise alpha=0 pour ne pas faire de régularisation\n",
    "\n",
    "    # On entraîne le modèle sur les données d'entraînement avec les variables sélectionnées\n",
    "    model_ordinal.fit(X_train, y_train)\n",
    "\n",
    "    # prédictions sur les données de test avec les variables sélectionnées\n",
    "    predictions_ordinal = model_ordinal.predict(X_test)\n",
    "\n",
    "    # Calcul de l'exactitude du modèle de régression logistique ordinale\n",
    "    accuracy_ordinal = accuracy_score(y_test, predictions_ordinal)\n",
    "\n",
    "   \n",
    "    print(\"Précision du modèle sur les données de test : {:.2f}%\".format(accuracy_ordinal * 100))\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle sur les données de test : 72.58%\n"
     ]
    }
   ],
   "source": [
    "model_training(X_train=X_train_lasso, X_test=X_test_lasso, y_train=y_train, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthodes de sélection de variables par critères AIC|BIC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ce notebook se concentre sur la sélection de modèles pour les modèles Lasso qui sont des modèles linéaires avec une pénalité L1 pour les problèmes de régression. Plusieurs stratégies peuvent être utilisées pour sélectionner la valeur du paramètre de régularisation : via une validation croisée ou en utilisant un critère d'information, à savoir AIC ou BIC.\n",
    "\n",
    "Dans ce qui suit, nous explorerons ces différentes stratégies. Ce notebook s'inspire de la source Lasso model selection: AIC-BIC / cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_sets(train_data, test_data):\n",
    "    \"\"\"Fonction qui récupère les dataframes train et test et retourne les vecteurs utiles pour la phase\n",
    "    d'entrainement et test.\n",
    "\n",
    "    Args:\n",
    "        train_data (DataFrame): données d'entrainement pré-traitées\n",
    "        test_data (DataFrame): données de test pré-traitées\n",
    "\n",
    "    Returns:\n",
    "        tuple: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train = train_data.drop(labels=[\"score\"], axis=1).values\n",
    "    y_train = train_data[\"score\"].values\n",
    "\n",
    "    X_test = test_data.drop(labels=[\"score\"], axis=1).values\n",
    "    y_test = test_data[\"score\"].values\n",
    "    \n",
    "\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_sets(train_data=df_train, test_data=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>saturated-fat_100g</th>\n",
       "      <th>trans-fat_100g</th>\n",
       "      <th>cholesterol_100g</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>vitamin-c_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20492</th>\n",
       "      <td>1502.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.787663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.019264</td>\n",
       "      <td>0.230625</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14016</th>\n",
       "      <td>788.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.198759</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.028080</td>\n",
       "      <td>0.132071</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39163</th>\n",
       "      <td>1234.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.020546</td>\n",
       "      <td>0.015637</td>\n",
       "      <td>18.75</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.8000</td>\n",
       "      <td>0.031769</td>\n",
       "      <td>0.710842</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>205.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.007910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.102756</td>\n",
       "      <td>0.015593</td>\n",
       "      <td>0.007031</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25451</th>\n",
       "      <td>508.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.028896</td>\n",
       "      <td>11.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.8000</td>\n",
       "      <td>0.037283</td>\n",
       "      <td>0.173588</td>\n",
       "      <td>0.007982</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37635</th>\n",
       "      <td>1983.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0.576880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.80</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.309437</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20225</th>\n",
       "      <td>1910.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.265686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>1.9304</td>\n",
       "      <td>0.067192</td>\n",
       "      <td>0.309656</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48693</th>\n",
       "      <td>2386.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.097566</td>\n",
       "      <td>0.015394</td>\n",
       "      <td>56.00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.053304</td>\n",
       "      <td>0.288824</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41378</th>\n",
       "      <td>2046.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.058257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.70</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.8100</td>\n",
       "      <td>0.060823</td>\n",
       "      <td>0.567159</td>\n",
       "      <td>0.008957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28549</th>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.080587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.191909</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34340 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy_100g  fat_100g  saturated-fat_100g  trans-fat_100g  \\\n",
       "20492       1502.0       2.0                0.47        0.787663   \n",
       "14016        788.0       7.1                2.20        0.198759   \n",
       "39163       1234.0      31.3                8.50        0.020546   \n",
       "5394         205.0       2.0                0.00        0.007910   \n",
       "25451        508.0       5.0                0.50        0.058824   \n",
       "...            ...       ...                 ...             ...   \n",
       "37635       1983.0      21.0                4.70        0.576880   \n",
       "20225       1910.0      19.4                1.70        0.265686   \n",
       "48693       2386.0      36.0               22.00        0.097566   \n",
       "41378       2046.0      18.4                4.50        0.058257   \n",
       "28549        201.0       0.0                0.00        0.080587   \n",
       "\n",
       "       cholesterol_100g  carbohydrates_100g  sugars_100g  fiber_100g  \\\n",
       "20492          0.000000               72.00          1.0    0.000000   \n",
       "14016          0.000563               20.00          2.3    2.700000   \n",
       "39163          0.015637               18.75          1.1    1.500000   \n",
       "5394           0.000000                9.10          2.0    0.000000   \n",
       "25451          0.028896               11.00          4.0    0.000000   \n",
       "...                 ...                 ...          ...         ...   \n",
       "37635          0.000000               25.80         28.0    3.600000   \n",
       "20225          0.000000               42.20          3.0   10.100000   \n",
       "48693          0.015394               56.00         55.0    1.333333   \n",
       "41378          0.000000               64.70          2.2    4.500000   \n",
       "28549          0.000000               10.00         10.0    0.400000   \n",
       "\n",
       "       salt_100g  vitamin-c_100g  calcium_100g  iron_100g  score  \n",
       "20492     1.0000        0.019264      0.230625   0.007938      2  \n",
       "14016     1.0000        0.028080      0.132071   0.005067      3  \n",
       "39163     1.8000        0.031769      0.710842   0.007000      1  \n",
       "5394      0.1300        0.102756      0.015593   0.007031      4  \n",
       "25451     1.8000        0.037283      0.173588   0.007982      2  \n",
       "...          ...             ...           ...        ...    ...  \n",
       "37635     0.6000        0.000016      0.309437   0.004825      1  \n",
       "20225     1.9304        0.067192      0.309656   0.006700      2  \n",
       "48693     0.1900        0.053304      0.288824   0.006360      0  \n",
       "41378     3.8100        0.060823      0.567159   0.008957      1  \n",
       "28549     0.0000        0.033000      0.191909   0.005506      2  \n",
       "\n",
       "[34340 rows x 13 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_variables = ['energy_100g', 'fat_100g', 'saturated-fat_100g', 'trans-fat_100g', 'cholesterol_100g', 'carbohydrates_100g', 'sugars_100g', 'fiber_100g', 'salt_100g', 'vitamin-c_100g', 'calcium_100g', 'iron_100g', 'score']\n",
    "\n",
    "df_train[liste_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.50200000e+03, 2.00000000e+00, 4.70000000e-01, ...,\n",
       "        1.92638554e-02, 2.30625000e-01, 7.93840580e-03],\n",
       "       [7.88000000e+02, 7.10000000e+00, 2.20000000e+00, ...,\n",
       "        2.80800000e-02, 1.32071429e-01, 5.06666667e-03],\n",
       "       [1.23400000e+03, 3.13000000e+01, 8.50000000e+00, ...,\n",
       "        3.17688772e-02, 7.10842105e-01, 7.00000000e-03],\n",
       "       ...,\n",
       "       [2.38600000e+03, 3.60000000e+01, 2.20000000e+01, ...,\n",
       "        5.33042169e-02, 2.88823529e-01, 6.36027515e-03],\n",
       "       [2.04600000e+03, 1.84000000e+01, 4.50000000e+00, ...,\n",
       "        6.08231047e-02, 5.67158730e-01, 8.95689655e-03],\n",
       "       [2.01000000e+02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        3.30000000e-02, 1.91908714e-01, 5.50622407e-03]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LassoLarsIC fournit un estimateur Lasso qui utilise le critère d'information d'Akaike (AIC) ou le critère d'information de Bayes (BIC) pour sélectionner la valeur optimale du paramètre de régularisation alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer l'erreur de classification\n",
    "def classification_error(y_true, y_pred):\n",
    "    return 1 - accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "## On normalise les données\n",
    "scaler = StandardScaler()\n",
    "X_train_ = scaler.fit_transform(X_train)\n",
    "X_test_ = scaler.transform(X_test)\n",
    "\n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(X_train_, y_train)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(X_train_, y_train)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "# Variables sélectionnées avec critère BIC\n",
    "indices_variables_bic = np.where(model_bic.coef_ != 0)[0]\n",
    "variables_bic = df_train.columns[indices_variables_bic]\n",
    "\n",
    "# Entraîner le modèle de régression logistique ordinale avec critère BIC\n",
    "model_ordinal_bic = LogisticAT(alpha=0)\n",
    "model_ordinal_bic.fit(X_train[:, indices_variables_bic], y_train)\n",
    "\n",
    "# Prédire les valeurs sur l'ensemble de test\n",
    "y_pred_bic = model_ordinal_bic.predict(X_test[:, indices_variables_bic])\n",
    "\n",
    "# statistiques bic\n",
    "r2_bic = r2_score(y_test, y_pred_bic)\n",
    "mse_bic = mean_squared_error(y_test, y_pred_bic)\n",
    "accuracy_bic = accuracy_score(y_test, y_pred_bic)\n",
    "\n",
    "# Variables sélectionnées avec critère AIC\n",
    "indices_variables_aic = np.where(model_aic.coef_ != 0)[0]\n",
    "variables_aic = df_train.columns[indices_variables_aic]\n",
    "\n",
    "# Entraîner le modèle de régression logistique ordinale avec critère AIC\n",
    "model_ordinal_aic = LogisticAT(alpha=0)\n",
    "model_ordinal_aic.fit(X_train[:, list(indices_variables_aic)], y_train)\n",
    "\n",
    "# Prédire les valeurs sur l'ensemble de test\n",
    "y_pred_aic = model_ordinal_aic.predict(X_test[:, list(indices_variables_aic)])\n",
    "\n",
    "# statistiques aic\n",
    "r2_aic = r2_score(y_test, y_pred_aic)\n",
    "mse_aic = mean_squared_error(y_test, y_pred_aic)\n",
    "accuracy_aic = accuracy_score(y_test, y_pred_aic)\n",
    "\n",
    "# Calculer l'erreur de classification pour les modèles AIC et BIC\n",
    "error_aic = classification_error(y_test, y_pred_aic)\n",
    "error_bic = classification_error(y_test, y_pred_bic)\n",
    "\n",
    "#Résultats\n",
    "results = pd.DataFrame({\n",
    "    \"Critère\": [\"AIC\", \"BIC\"],\n",
    "    \"Variables Sélectionnées\": [list(variables_aic), list(variables_bic)],\n",
    "    \"R²\": [r2_aic, r2_bic],\n",
    "    \"MSE\": [mse_aic, mse_bic],\n",
    "    \"Accuracy model ordinal\": [accuracy_aic, accuracy_bic],\n",
    "    \"Classification Error\": [error_aic, error_bic],\n",
    "    \"Alpha (AIC)\": [alpha_aic_, np.nan],  # Notez que la valeur de l'alpha pour BIC est obtenue de la même manière\n",
    "    \"Alpha (BIC)\": [np.nan, alpha_bic_]\n",
    "})\n",
    "\n",
    "def highlight_min(s):\n",
    "    is_min = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_min]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On regarde les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_414fd_row0_col6, #T_414fd_row1_col7 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_414fd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_414fd_level0_col0\" class=\"col_heading level0 col0\" >Critère</th>\n",
       "      <th id=\"T_414fd_level0_col1\" class=\"col_heading level0 col1\" >Variables Sélectionnées</th>\n",
       "      <th id=\"T_414fd_level0_col2\" class=\"col_heading level0 col2\" >R²</th>\n",
       "      <th id=\"T_414fd_level0_col3\" class=\"col_heading level0 col3\" >MSE</th>\n",
       "      <th id=\"T_414fd_level0_col4\" class=\"col_heading level0 col4\" >Accuracy model ordinal</th>\n",
       "      <th id=\"T_414fd_level0_col5\" class=\"col_heading level0 col5\" >Classification Error</th>\n",
       "      <th id=\"T_414fd_level0_col6\" class=\"col_heading level0 col6\" >Alpha (AIC)</th>\n",
       "      <th id=\"T_414fd_level0_col7\" class=\"col_heading level0 col7\" >Alpha (BIC)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_414fd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_414fd_row0_col0\" class=\"data row0 col0\" >AIC</td>\n",
       "      <td id=\"T_414fd_row0_col1\" class=\"data row0 col1\" >['energy_100g', 'fat_100g', 'saturated-fat_100g', 'trans-fat_100g', 'cholesterol_100g', 'carbohydrates_100g', 'sugars_100g', 'fiber_100g', 'proteins_100g', 'salt_100g', 'sodium_100g', 'vitamin-a_100g', 'vitamin-c_100g', 'calcium_100g', 'iron_100g']</td>\n",
       "      <td id=\"T_414fd_row0_col2\" class=\"data row0 col2\" >0.831980</td>\n",
       "      <td id=\"T_414fd_row0_col3\" class=\"data row0 col3\" >0.334886</td>\n",
       "      <td id=\"T_414fd_row0_col4\" class=\"data row0 col4\" >0.702388</td>\n",
       "      <td id=\"T_414fd_row0_col5\" class=\"data row0 col5\" >0.297612</td>\n",
       "      <td id=\"T_414fd_row0_col6\" class=\"data row0 col6\" >0.000000</td>\n",
       "      <td id=\"T_414fd_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_414fd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_414fd_row1_col0\" class=\"data row1 col0\" >BIC</td>\n",
       "      <td id=\"T_414fd_row1_col1\" class=\"data row1 col1\" >['energy_100g', 'fat_100g', 'saturated-fat_100g', 'trans-fat_100g', 'cholesterol_100g', 'carbohydrates_100g', 'sugars_100g', 'fiber_100g', 'proteins_100g', 'salt_100g', 'vitamin-a_100g', 'vitamin-c_100g', 'calcium_100g', 'iron_100g']</td>\n",
       "      <td id=\"T_414fd_row1_col2\" class=\"data row1 col2\" >0.834902</td>\n",
       "      <td id=\"T_414fd_row1_col3\" class=\"data row1 col3\" >0.329062</td>\n",
       "      <td id=\"T_414fd_row1_col4\" class=\"data row1 col4\" >0.707513</td>\n",
       "      <td id=\"T_414fd_row1_col5\" class=\"data row1 col5\" >0.292487</td>\n",
       "      <td id=\"T_414fd_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_414fd_row1_col7\" class=\"data row1 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x217a9b272b0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.style.apply(highlight_min, subset=[\"Alpha (AIC)\", \"Alpha (BIC)\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On dirait que les modèles donnent à peu près la même chose.\n",
    "Cependant, le modèle optimal au sens du BIC donne un meilleur modèle que celui au sens de l'AIC car affiche une erreur de classification plus faible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['energy_100g',\n",
       " 'fat_100g',\n",
       " 'saturated-fat_100g',\n",
       " 'trans-fat_100g',\n",
       " 'cholesterol_100g',\n",
       " 'carbohydrates_100g',\n",
       " 'sugars_100g',\n",
       " 'fiber_100g',\n",
       " 'proteins_100g',\n",
       " 'salt_100g',\n",
       " 'vitamin-a_100g',\n",
       " 'vitamin-c_100g',\n",
       " 'calcium_100g',\n",
       " 'iron_100g']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Variables sélectionnées par le critère BIC\n",
    "results[\"Variables Sélectionnées\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients du modèle optimal au sens du BIC:\n",
      "energy_100g: -0.001210366538994659\n",
      "fat_100g: -0.06318952650259746\n",
      "saturated-fat_100g: -0.3926341463073361\n",
      "trans-fat_100g: -1.7524813352994169\n",
      "cholesterol_100g: -0.2738357542441615\n",
      "carbohydrates_100g: -0.0024272228238948136\n",
      "sugars_100g: -0.12955563238100962\n",
      "fiber_100g: 0.4694123287145111\n",
      "proteins_100g: 0.04014568266620962\n",
      "salt_100g: -1.681459233553816\n",
      "vitamin-a_100g: 0.0031130506281653015\n",
      "vitamin-c_100g: 0.060925164001909546\n",
      "calcium_100g: -0.5689939006249928\n",
      "iron_100g: 1.0957672907789342\n"
     ]
    }
   ],
   "source": [
    "# Afficher les coefficients du modèle optimal au sens du BIC\n",
    "coefficients_bic = model_ordinal_bic.coef_\n",
    "print(\"Coefficients du modèle optimal au sens du BIC:\")\n",
    "for variable, coefficient in zip(variables_bic, coefficients_bic):\n",
    "    print(f\"{variable}: {coefficient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.26%\n"
     ]
    }
   ],
   "source": [
    "#Application du modèle\n",
    "model = LogisticAT(alpha=alpha_bic_)\n",
    "model.fit(X_train[:, list(indices_variables_bic)], y_train)\n",
    "\n",
    "# Effectuez les prédictions sur les données de test\n",
    "predictions = model.predict(X_test[:, indices_variables_bic])\n",
    "\n",
    "# Calculez l'exactitude des prédictions\n",
    "accuracy_ordinal = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Imprimez le pourcentage de précision\n",
    "print(\"{:.2f}%\".format(accuracy_ordinal * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
