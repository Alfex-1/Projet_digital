{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ce notebook rassemble les méthodes statistiques employées pour la sélection de variables pour le modèle de régression logistique ordinale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mord import LogisticAT\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mord import LogisticAT\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../data/train.csv\")\n",
    "df_test = pd.read_csv(\"../../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_sets(train_data, test_data):\n",
    "    \"\"\"Fonction qui récupère les dataframes train et test et retourne les vecteurs utiles pour la phase\n",
    "    d'entrainement et test.\n",
    "\n",
    "    Args:\n",
    "        train_data (DataFrame): données d'entrainement pré-traitées\n",
    "        test_data (DataFrame): données de test pré-traitées\n",
    "\n",
    "    Returns:\n",
    "        tuple: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train = train_data.drop(labels=[\"score\"], axis=1).values\n",
    "    y_train = train_data[\"score\"].values\n",
    "\n",
    "    X_test = test_data.drop(labels=[\"score\"], axis=1).values\n",
    "    y_test = test_data[\"score\"].values\n",
    "    \n",
    "    ## On normalise les données\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_sets(train_data=df_train, test_data=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le modèle de régression logistique ordinale initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On regarde les coefficients et l'erreur de classification du modèle global initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On entraîne le modèle initial\n",
    "\n",
    "def model_training(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Fonction pour entrainer le modèle de régression logistique ordinale\n",
    "\n",
    "    Args:\n",
    "        X_train (Array): \n",
    "        X_test (Array): \n",
    "        y_train (Array): \n",
    "        y_test (Array): \n",
    "    \"\"\"\n",
    "\n",
    "    # Maintenant, on utilise les variables sélectionnées pour la régression logistique ordinale avec mord\n",
    "    model_ordinal = LogisticAT(alpha=0)  # On utilise alpha=0 pour ne pas faire de régularisation\n",
    "\n",
    "    # On entraîne le modèle sur les données d'entraînement avec les variables sélectionnées\n",
    "    model_ordinal.fit(X_train, y_train)\n",
    "\n",
    "    # prédictions sur les données de test avec les variables sélectionnées\n",
    "    predictions_ordinal = model_ordinal.predict(X_test)\n",
    "\n",
    "    # Calcul de l'exactitude du modèle de régression logistique ordinale\n",
    "    accuracy_ordinal = accuracy_score(y_test, predictions_ordinal)\n",
    "    \n",
    "    print(\"Coefficients du modèle de régression logistique :\")\n",
    "    print(model_ordinal.coef_)\n",
    "   \n",
    "    print(\"Précision du modèle sur les données de test : {:.2f}%\".format(accuracy_ordinal * 100))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On l'applique et on montre ses coefficients et son erreur de classification\n",
    "model_training(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthodes de sélection de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *1-* Sélection par régression Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegressionCV est utilisé pour effectuer une régression logistique avec une validation croisée pour sélectionner le meilleur paramètre de régularisation (C) parmi une liste de valeurs candidates ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_lasso(train_data, test_data, max_iter = 1000, seuil=0.2):\n",
    "    \"\"\"Fonction pour faire la sélection de variables en se basant sur un modèle Lasso.\n",
    "\n",
    "    Args:\n",
    "        train_data (Dataframe): données préparées pour le train\n",
    "        test_data (DataFrame): données préparées pour le test\n",
    "        max_iter (int, optional): Nombre d'itérations pour obtenir la convergence, par défaut 1000\n",
    "        seuil (float, optional): Valeur seuil en valeur absolur au dessus de laquelle on sélectionn les variables. Par défaut 0.2.\n",
    "\n",
    "    Returns:\n",
    "        tuple: variables_lasso (Liste) noms des variables choisies, X_train_final (Array), X_test_final (Array), y_train(Array), y_test (Array)\n",
    "        vecteurs des variables choisies\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = get_train_test_sets(train_data=train_data, test_data=test_data)\n",
    "    \n",
    "\n",
    "\n",
    "    # modèle de régression logistique avec pénalité L1 (LASSO)\n",
    "    model_lasso = LogisticRegression(penalty='l1', solver='saga', max_iter=max_iter, random_state=None)\n",
    "\n",
    "    # SelectFromModel pour récupérer les paramètres du modèle\n",
    "    sfm = SelectFromModel(estimator=model_lasso)\n",
    "    sfm.fit(X_train, y_train)\n",
    "\n",
    "    # indices des variables sélectionnées\n",
    "    indices_lasso = sfm.get_support(indices=True)\n",
    "    \n",
    "    # noms des variables correspondantes dans les données\n",
    "    variables = [train_data.columns[i] for i in indices_lasso]\n",
    "    \n",
    "    # coefficients des variables sélectionnées\n",
    "    coefficients_lasso = sfm.estimator_.coef_.flatten()\n",
    "\n",
    "    # noms et coefficients des variables\n",
    "    print(\"#########################################################\")\n",
    "    print()\n",
    "    print(\"Coefficients obtenus après Lasso:\")\n",
    "    for variable, coefficient in zip(variables, coefficients_lasso):\n",
    "        print(f\"{variable}: {coefficient}\")\n",
    "\n",
    "    # On pénalise en ne prenant que les coeffs différents au dessus du seuil passé en argument\n",
    "    indices_choisis = [i for i, coef in zip(indices_lasso, coefficients_lasso) if abs(coef) > seuil]\n",
    "\n",
    "    # variables correspondantes aux indices choisies\n",
    "    variables_lasso = [train_data.columns[i] for i in indices_choisis]\n",
    "\n",
    "    print(\"##########################################################\")\n",
    "    print()\n",
    "    print(\"Variables sélectionnées après Lasso\")\n",
    "    print()\n",
    "    for variable in variables_lasso:\n",
    "        print(f\"{variable}\")\n",
    "\n",
    "\n",
    "    # on utilise les indices filtrés pour obtenir les données des variables optimales sélectionnées\n",
    "    X_train_final = X_train[:, indices_choisis]\n",
    "    X_test_final = X_test[:, indices_choisis]\n",
    "    \n",
    "    return variables_lasso, X_train_final, X_test_final, y_train, y_test \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On effectue la sélection de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################################\n",
      "\n",
      "Coefficients obtenus après Lasso:\n",
      "energy_100g: 0.0\n",
      "fat_100g: 0.2312759394181233\n",
      "saturated-fat_100g: 2.020391817385482\n",
      "trans-fat_100g: 0.8203335309026503\n",
      "cholesterol_100g: 1.251817937524018\n",
      "carbohydrates_100g: 0.0\n",
      "sugars_100g: 1.6820724367932676\n",
      "fiber_100g: -0.847604921358526\n",
      "proteins_100g: 0.09164171790418724\n",
      "salt_100g: 0.5031184929786225\n",
      "sodium_100g: 0.5023665030859524\n",
      "vitamin-a_100g: 0.3783509923197762\n",
      "vitamin-c_100g: 0.31518011118007916\n",
      "calcium_100g: -0.05431301772506332\n",
      "iron_100g: 0.0\n",
      "nutrition-score-fr_100g: 13.76347393595731\n",
      "code: 0.20051679584593599\n",
      "##########################################################\n",
      "\n",
      "Variables sélectionnées après Lasso\n",
      "\n",
      "fat_100g\n",
      "saturated-fat_100g\n",
      "trans-fat_100g\n",
      "cholesterol_100g\n",
      "sugars_100g\n",
      "fiber_100g\n",
      "salt_100g\n",
      "sodium_100g\n",
      "vitamin-a_100g\n",
      "vitamin-c_100g\n",
      "nutrition-score-fr_100g\n",
      "code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaure\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_, X_train_lasso, X_test_lasso, y_train, y_test = selection_lasso(train_data=df_train, test_data=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(X_train, X_test, y_train, y_test, selection_method = 'lasso'):\n",
    "    \"\"\"Fonction pour entrainer le modèle de régression logistique ordinale\n",
    "\n",
    "    Args:\n",
    "        X_train (Array): \n",
    "        X_test (Array): \n",
    "        y_train (Array): \n",
    "        y_test (Array): \n",
    "    \"\"\"\n",
    "\n",
    "    # Maintenant, on utilise les variables sélectionnées pour la régression logistique ordinale avec mord\n",
    "    model_ordinal = LogisticAT(alpha=0)  # On utilise alpha=0 pour ne pas faire de régularisation\n",
    "\n",
    "    # On entraîne le modèle sur les données d'entraînement avec les variables sélectionnées\n",
    "    model_ordinal.fit(X_train, y_train)\n",
    "\n",
    "    # prédictions sur les données de test avec les variables sélectionnées\n",
    "    predictions_ordinal = model_ordinal.predict(X_test)\n",
    "\n",
    "    # Calcul de l'exactitude du modèle de régression logistique ordinale\n",
    "    accuracy_ordinal = accuracy_score(y_test, predictions_ordinal)\n",
    "\n",
    "    print()\n",
    "    print(\"Précision du modèle sur les données de test : {:.2f}%\".format(accuracy_ordinal * 100))\n",
    "    print()\n",
    "\n",
    "    print(\"#####################################\")\n",
    "    print()\n",
    "    print(\"Enregistrement du modèle de régression logistique\")\n",
    "    with open(f\"../model/modele_ordinal_{X_test_lasso}.pkl\", 'wb') as model_file:\n",
    "        pickle.dump(model_ordinal, model_file)\n",
    "\n",
    "    print(\"Modèle ordinal enregistré\")\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine le modèle sur les variables sélectionnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exactitude du modèle de régression logistique ordinale : 100.00%\n",
      "\n",
      "#####################################\n",
      "\n",
      "Enregistrement du modèle de régression logistique\n",
      "Modèle ordinal enregistré\n"
     ]
    }
   ],
   "source": [
    "model_training(X_train=X_train_lasso, X_test=X_test_lasso, y_train=y_train, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-test du modèle enregistré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00%\n"
     ]
    }
   ],
   "source": [
    "with open('../model/modele_ordinal.pkl', 'rb') as model_file:\n",
    "    model_ordinal = pickle.load(model_file)\n",
    "    \n",
    "predictions = model_ordinal.predict(X_test_lasso)\n",
    "accuracy_ordinal = accuracy_score(y_test, predictions)\n",
    "print(\"{:.2f}%\".format(accuracy_ordinal * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *2-* Sélection par Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_selection(train_data, test_data, expected_nb_var, nb_estimator =100):\n",
    "    \"\"\"Fonction pour faire de la sélection de variables en fonction de l'importance des variables obtenues en\n",
    "    utilisant une modèle de RandomForestClassifier\n",
    "\n",
    "    Args:\n",
    "        train_data (DataFrame): dataframe d'entrainement\n",
    "        test_data (DataFrame): dataframe de test\n",
    "        expected_nb_var (int): nombre de variables qu'on souhaite obtenir\n",
    "        nb_estimator (int) : nombres d'arbres dans la forêt\n",
    "    \"\"\"\n",
    "\n",
    "    # on obtient les matrices (train & test) à passer dans le modèle\n",
    "    X_train, X_test, y_train, y_test = get_train_test_sets(train_data=train_data, test_data=test_data)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "\n",
    "    # modèle Random Forest avec bootstrap\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=nb_estimator, random_state=None, bootstrap=True, criterion='gini')\n",
    "    \"\"\" n-estimators : On aura donc 100 arbres qui seront tous légèrement différents\n",
    "    \n",
    "        bootstrap : construire de nouveaux échantillons par tirage aléatoire avec remise\n",
    "        \n",
    "        criterion = 'gini' : L'indice de Gini mesure l'impureté d'un nœud (une division) \n",
    "        dans un arbre de décision. Plus précisément, il évalue à quel point un nœud est mélangé en termes de classes de la cible\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Entraînement du modèle sur les données\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Importance des variables à partir du modèle\n",
    "    feature_importances = rf_model.feature_importances_\n",
    "\n",
    "    # Sélection des indices des variables importantes (les nvar premières)\n",
    "    important_indices = feature_importances.argsort()[-expected_nb_var:][::-1]\n",
    "    \n",
    "    variables_rf = [train_data.columns[i] for i in important_indices]\n",
    "    \n",
    "    print(\"##########################################################\")\n",
    "    print()\n",
    "    print(\"Variables sélectionnées après Random Forest\")\n",
    "    print()\n",
    "    for variable in variables_rf:\n",
    "        print(f\"{variable}\")\n",
    "\n",
    "    # Matrices d'entrainement et de test pour entrainer le modèle logistique\n",
    "    X_train_rf = X_train[:, important_indices]\n",
    "    X_test_rf = X_test[:, important_indices]\n",
    "    \n",
    "    return variables_rf, X_train_rf, X_test_rf, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "\n",
      "Variables sélectionnées après Random Forest\n",
      "\n",
      "nutrition-score-fr_100g\n",
      "trans-fat_100g\n",
      "saturated-fat_100g\n",
      "calcium_100g\n",
      "fat_100g\n",
      "cholesterol_100g\n",
      "energy_100g\n",
      "code\n",
      "sugars_100g\n",
      "vitamin-c_100g\n"
     ]
    }
   ],
   "source": [
    "_, X_train_rf, X_test_rf, y_train, y_test = random_forest_selection(train_data=df_train, test_data=df_test, nvar=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
